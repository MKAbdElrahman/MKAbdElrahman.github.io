<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Software Architecture on Mohamed Abdelrahman</title>
    <link>http://localhost:1313/categories/software-architecture/</link>
    <description>Recent content in Software Architecture on Mohamed Abdelrahman</description>
    <generator>Hugo</generator>
    <language>en</language>
    <lastBuildDate>Tue, 09 Jul 2024 00:00:00 +0000</lastBuildDate>
    <atom:link href="http://localhost:1313/categories/software-architecture/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Sagas Quantatively: Fantasy Fiction</title>
      <link>http://localhost:1313/posts/saga-fantasyfiction/</link>
      <pubDate>Tue, 09 Jul 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/saga-fantasyfiction/</guid>
      <description>&lt;p&gt;Last time, we discussed the first saga cataloged by Mark Richards and Neal Ford in their book, &amp;ldquo;Software Architecture: The Hard Parts&amp;rdquo;. We saw how the epic saga is exponentially sensitive to the availabilities of the orchestrator and the orchestrated services. We also noted how latency worsens with increasing availability due to the sequential blocking model.  Today, we will discuss the second saga they called the fantasy fiction saga. In this saga, we switch from a blocking communication model to a non-blocking one while maintaining the atomicity constraint.  In a previous post, I discussed why we should avoid using the terms synchronous and asynchronous, and instead use more explicit terms like blocking request-reply, non-blocking request-reply, and event-driven. Let’s apply these concepts to the fantasy fiction saga.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Sagas Quantatively: Epic Saga</title>
      <link>http://localhost:1313/posts/saga-epic/</link>
      <pubDate>Wed, 03 Jul 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/saga-epic/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/images/saga/epic-saga.png&#34; alt=&#34;alt text&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;When we transition to microservices, each service owns its data. Achieving transactions across multiple services isn&amp;rsquo;t as straightforward as with a single monolithic database.&lt;/p&gt;&#xA;&lt;p&gt;One way to address this challenge is through sagas, which simulate distributed transactions using a series of local transactions. This approach was popularized by Chris Richardson and later analyzed by Mark Richards and Neal Ford in their book &amp;lsquo;Sotware Architecture: The Hard Parts&amp;rsquo;.&lt;/p&gt;&#xA;&lt;p&gt;They examined how these factors affect saga characteristics:&lt;/p&gt;</description>
    </item>
    <item>
      <title>Microservices: Why Not a Shared Monolithic Database?</title>
      <link>http://localhost:1313/posts/why-not-shared-db/</link>
      <pubDate>Fri, 28 Jun 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/why-not-shared-db/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/images/microservices/shared-db.png&#34; alt=&#34;alt text&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;In microservices, the idea of using a shared monolithic database is always rejected. There are several reasons why this approach is not advisable. Below are the key considerations that highlight the drawbacks of a shared monolithic database.&lt;/p&gt;&#xA;&lt;h3 id=&#34;change-control&#34;&gt;Change Control&lt;/h3&gt;&#xA;&lt;p&gt;Managing changes in a shared monolithic database is a complex task. Any schema change necessitates coordination across all dependent services, which can be cumbersome and time-consuming. This coordination is required to ensure that all services are redeployed simultaneously to prevent schema mismatch errors, which can cause significant downtime and service disruption.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Data Sharing Between Microservices Using Synchronized Embedded Caches</title>
      <link>http://localhost:1313/posts/caching_data-shraing-embedded-cache/</link>
      <pubDate>Thu, 27 Jun 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/caching_data-shraing-embedded-cache/</guid>
      <description>&lt;h3 id=&#34;setting-the-scene&#34;&gt;Setting the Scene&lt;/h3&gt;&#xA;&lt;p&gt;&lt;img src=&#34;http://localhost:1313/images/caching/data-sharing-embedded.png&#34; alt=&#34;alt text&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;Consider an online food delivery system with two essential microservices:&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&lt;strong&gt;Menu Service&lt;/strong&gt;: Manages the list of available dishes.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Order Service&lt;/strong&gt;: Allows customers to create and manage their orders.&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;h3 id=&#34;how-it-works&#34;&gt;How It Works&lt;/h3&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;strong&gt;Starting the Menu Service&lt;/strong&gt;:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;The menu service starts and loads a cache containing information about available dishes.&lt;/li&gt;&#xA;&lt;li&gt;This cache is distributed, enabling it to be shared across different services.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;strong&gt;Starting the Order Service&lt;/strong&gt;:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;When the order service starts, it recognizes the cache used by the menu service.&lt;/li&gt;&#xA;&lt;li&gt;The system facilitates a handshake between the services, allowing them to join the same cluster and establish a connection.&lt;/li&gt;&#xA;&lt;li&gt;Both services now know about each other. The menu service’s cache includes the list of dishes, and the order service synchronizes with this cache.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;h3 id=&#34;demonstrating-synchronization&#34;&gt;Demonstrating Synchronization&lt;/h3&gt;&#xA;&lt;p&gt;Here’s how the two services interact:&lt;/p&gt;</description>
    </item>
    <item>
      <title>Caching: Topologies and Patterns</title>
      <link>http://localhost:1313/posts/caching_patterns/</link>
      <pubDate>Wed, 26 Jun 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/caching_patterns/</guid>
      <description>&lt;h2 id=&#34;what-is-a-cache&#34;&gt;What is a Cache?&lt;/h2&gt;&#xA;&lt;p&gt;A cache is a secondary data store that’s faster to read from than the data’s primary store. The purpose of a cache is to improve application performance by:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Reducing network calls to the primary data store:&lt;/strong&gt; Instead of repeatedly querying the database, the cache handles data retrieval, offloading processing from the database. This reduces database connection consumption, often a limiting factor, and allows the database to perform faster.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Increasing performance:&lt;/strong&gt; Data in a cache is typically stored in random-access memory (RAM), providing quicker access than querying a database.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;In distributed databases, the performance enhancement might be marginal due to network call latency, but the increase in scalability can be significant.&lt;/p&gt;</description>
    </item>
    <item>
      <title>EDA Patterns: Thin and Thick Events</title>
      <link>http://localhost:1313/posts/eda-patterns-thin-thick-events/</link>
      <pubDate>Thu, 02 May 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/eda-patterns-thin-thick-events/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/images/thin-thick-event.svg&#34; alt=&#34;thin and thick events&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;Event-driven systems (EDS) rely on exchanging events for communication. Other services &lt;strong&gt;subscribe&lt;/strong&gt; to these events and react accordingly. This loose coupling keeps services unaware of each other, with the only connection being the event&amp;rsquo;s data format. Since events act as contracts, careful design and consideration for future changes are crucial.&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;Scenario:&lt;/strong&gt; Imagine an e-commerce application. When a customer submits an order, the order service emits an &amp;ldquo;order-requested&amp;rdquo; event. Both the payment service and inventory service are interested in this event. The question is, what format should this event take?&lt;/p&gt;</description>
    </item>
    <item>
      <title>EDA Patterns: The Single Writer Principle</title>
      <link>http://localhost:1313/posts/eda-single-write-principle/</link>
      <pubDate>Mon, 29 Apr 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/eda-single-write-principle/</guid>
      <description>&lt;p&gt;The Single Writer Principle states that only one service should be responsible for making changes to a specific type of data or event.&lt;/p&gt;&#xA;&lt;p&gt;Let&amp;rsquo;s consider an e-commerce system with separate services for Orders, Payments, and Shipments. In this scenario, the Order service serves as the single writer for all order-related data. Here&amp;rsquo;s how it works:&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;When a customer clicks &amp;ldquo;buy,&amp;rdquo; the Basket service triggers an &amp;ldquo;Order Requested&amp;rdquo; event.&lt;/li&gt;&#xA;&lt;li&gt;The Order service receives this event, validates the order details, and publishes an &amp;ldquo;Order Confirmed&amp;rdquo; event if successful.&lt;/li&gt;&#xA;&lt;li&gt;Other services, such as Payments and Shipments, subscribe to relevant events and take necessary actions upon receiving them (e.g., processing payment or preparing shipment).&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;The Order service orchestrates these actions, ensuring that all changes to order data are coordinated and consistent.&lt;/p&gt;</description>
    </item>
    <item>
      <title>EDA Patterns: Event sourcing &amp; CQRS</title>
      <link>http://localhost:1313/posts/cqrs/</link>
      <pubDate>Sat, 27 Apr 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/cqrs/</guid>
      <description>&lt;p&gt;Event sourcing is a data management approach that centers around events, recognizing them as the core building blocks of any system. These events, representing state changes, are stored in an immutable append-only log, preserving the order they occurred in. This approach offers a comprehensive audit trail of the system&amp;rsquo;s activity and allows replaying the event log to reconstruct the current system state.&lt;/p&gt;&#xA;&lt;p&gt;CQRS, or Command Query Responsibility Segregation, complements event sourcing by advocating for the separation of write operations (commands) and read operations (queries). This decoupling brings several advantages. Firstly, it allows for independent optimization of the write model, which might prioritize high throughput like Kafka, and the read model, which might focus on fast queries like a traditional database. Secondly, CQRS facilitates independent scaling of the read and write models based on their specific needs.&lt;/p&gt;</description>
    </item>
    <item>
      <title>EDA Patterns: Idempotent Integration with a Third-Party REST API</title>
      <link>http://localhost:1313/posts/idempotentintegrationwithathird-partyrestapi/</link>
      <pubDate>Fri, 26 Apr 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/idempotentintegrationwithathird-partyrestapi/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/images/idempotent-integration.png&#34; alt=&#34;IdempotentIntegrationwithaThird-PartyRESTAPI&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;Scenario:&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;You have an event-driven application that needs to integrate with a third-party REST API (Service B) without modifying it. To ensure reliable message processing, you want to introduce Service A as a mediator that consumes events and interacts with Service B in an idempotent manner.&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;Idempotency Requirement:&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Service A:&lt;/strong&gt;  Service A must be idempotent to prevent duplicate event processing. This means if the same event is received multiple times, Service A should only process it once.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Service B:&lt;/strong&gt; Ideally, the calls from Service A to Service B should also be idempotent. This ensures that even if a request is retried due to network issues, it won&amp;rsquo;t cause unintended side effects on Service B.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;&lt;strong&gt;Solution:&lt;/strong&gt;&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
